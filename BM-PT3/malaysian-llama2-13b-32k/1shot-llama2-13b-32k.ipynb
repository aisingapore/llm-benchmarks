{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc3b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/mesolitica/malaysian-dataset/master/llm-benchmark/BM-pt3/BM-A-pt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c00f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-11 01:12:35,418] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c0e35b4ee24147a52945d1c56e1668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mesolitica/llama-13b-hf-32768-fpf')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'mesolitica/llama-13b-hf-32768-fpf', \n",
    "    use_flash_attention_2 = True, \n",
    "    torch_dtype = torch.float16,\n",
    "    device_map=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f147d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e306ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BM-A-pt3') as fopen:\n",
    "    text = fopen.read()\n",
    "    \n",
    "questions = []\n",
    "for t in text.split('no: ')[1:]:\n",
    "    t = t.strip()\n",
    "    no = t.split('\\n')[0]\n",
    "    objektif = t.split('objektif: ')[1].split('\\n')[0]\n",
    "    soalan = t.split('soalan:')[1].split('jawapan:')[0].strip()\n",
    "    jawapan = t.split('jawapan: ')[1].split(',')[0].strip()\n",
    "    data = {\n",
    "        'no': no,\n",
    "        'objektif': objektif,\n",
    "        'soalan': soalan,\n",
    "        'jawapan': jawapan,\n",
    "    }\n",
    "    questions.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd34f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "arange = set(range(len(questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4ba876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_prompt(row, answer = False):\n",
    "    if answer:\n",
    "        prompt = f\"\"\"\n",
    "objektif: {row['objektif']}\n",
    "soalan: {row['soalan']}\n",
    "jawapan: {row['jawapan']}\n",
    "    \"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "objektif: {row['objektif']}\n",
    "soalan: {row['soalan']}\n",
    "jawapan:\n",
    "    \"\"\"\n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce790522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contoh soalan 1\n",
      "objektif: Baca petikan di bawah ini dengan teliti, kemudian jawab soalan-soalan yang berikut.\n",
      "soalan: Maka diambil padi yang dijemur itu segenggam, lalu disembunyikan butir-butir padi itu di\n",
      "dalam lubang-lubang luka pada tumitnya. Setelah itu ia pun meminta izin dengan baik-\n",
      "baik untuk pulang ke kampungnya, ke bumi tempat saudaranya yang tetap menantinya.\n",
      "Maka berkatalah induk semangnya, orang kayangan yang masih juga mencurigainya\n",
      "itu, \"Baiklah jikalau kamu ingin pulang ke kampung kamu, akan tetapi, sebelum itu saya\n",
      "akan memeriksa dan menggeledah kamu lebih dahulu. Barangkali ada padi yang\n",
      "disembunyikan untuk kamu bawa sebagai oleh-oleh ke bumi.\"\n",
      "Anak yatim piatu itu pun menjawab dengan tenangnya, \"Silakan ! Periksalah dengan\n",
      "teliti kalau-kalau ada apa-apa yang saya bawa. Sekarang saya sudah betul-betul jera\n",
      "mengambil apa-apa. Saya sungguh-sungguh sudah bertaubat dan tidak mahu lagi\n",
      "melakukannya.\"\n",
      "Kemudian induk semang berkata, \"Jikalau benar demikian katamu, maka jelaslah bagi\n",
      "kami dan percayalah kami bahawa kamu betul-betul tidak akan mencuri padi kami lagi.\"\n",
      "Setelah induk semang berkata demikian, maka anak yatim piatu itu pun berangkatlah\n",
      "meninggalkan kayangan. Orang kayangan itu tidak mengetahui sama sekali bahawa anak\n",
      "yatim paitu yang kecil itu ada menyembunyikan padi di dalam lubang-lubang luka pada\n",
      "tumitnya. Akhirnya sampai jugalah anak yatim piatu itu dengan selamat di kampungnya.\n",
      "Maka ia pun dengan segera membuat ladang. Setelah selesai, ditanamnya padi yang\n",
      "dicurinya itu di ladangnya.\n",
      "\n",
      "Apakah nilai murni yang terdapat dalam petikan prosa tradisional di atas?\n",
      "\n",
      "A. Nilai keikhlasan\n",
      "B. Nilai keberanian\n",
      "C. Nilai kejujuran\n",
      "D. Nilai ketabahan\n",
      "jawapan: B\n",
      "\n",
      "objektif: Lengkapkan ayat-ayat yang berikut dengan memilih jawapan yang paling sesuai.\n",
      "soalan: Para ___ tanah air telah dihantar ke negara Jepun untuk membantu mangsa gempa bumi dan tsunami.\n",
      "A. hartawan\n",
      "B. dermawan\n",
      "C. bangsawan\n",
      "D. sukarelawan\n",
      "jawapan:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_398962/1150135202.py:2: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  shots = random.sample(arange - {i}, 1)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "shots = random.sample(arange - {i}, 1)\n",
    "prompts = []\n",
    "for no, s in enumerate(shots):\n",
    "    prompts.append(f'Contoh soalan {no + 1}\\n' + convert_prompt(questions[s], answer = True))\n",
    "\n",
    "prompts.append(convert_prompt(questions[i]))\n",
    "prompt = '\\n\\n'.join(prompts)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9201a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1281,   517, 29882,   577,   284,   273, 29871, 29896,    13,   711,\n",
       "          9761,   361, 29901,   350, 11989,  5697,  7941,   652,   289,  1450,\n",
       "           801,   297, 29875,   972,  6249, 13547,  4812, 29892,   413,   331,\n",
       "           566,   713,   432,  1450,   370,   577,   284,   273, 29899,   578,\n",
       "           284,   273,   343,   574,  7655,   638,   329, 29889,    13,   578,\n",
       "           284,   273, 29901,   341,  8245,   652,  1117,   309,   282, 10129,\n",
       "           343,   574,   652, 12701,   332,   372, 29884,  2377,   996, 29887,\n",
       "           314, 29892,   301, 22349,   766,  1590,   348, 29891,  7941,   541,\n",
       "           381, 29899,  4187,   381,   282, 10129,   372, 29884,   652,    13,\n",
       "         12293,   314, 14757,   574, 29899, 29870,   574,  8092,  1335,   282,\n",
       "          1114, 21622,   277,  1460, 29874, 29889,  3789,   295,   801,   372,\n",
       "         29884, 29871,   423,  6035,  2626, 15073,  5951,   262,   972,  6249,\n",
       "          9922,   638, 29899,    13,  2291,   638,   443, 29873,  2679,  9505,\n",
       "           574,  1589,   413,  1160,   686,  1460, 29874, 29892,  1589,   289,\n",
       "         15547,  1350,  5031,   872,   566,   279, 20912,   343,   574,   260,\n",
       "           300,   481,  1757, 13027,  3761, 29889,    13, 29924,  8245,   289,\n",
       "          5968,  2075,   801,  9013, 29895,  3031,   574,  1460, 29874, 29892,\n",
       "           470,   574,   413,   388,   574,   273,   343,   574,  5516,  4861,\n",
       "          8740, 29874,  1757,  2764,   335,   475,  3761,    13,  1981, 29892,\n",
       "           376, 29933, 29874,   638,  8083,   432, 23587,   585,  9286, 29884,\n",
       "          2348,   262,  9505,   574,  1589,   413,  1160,   686,  9286, 29884,\n",
       "         29892,   263, 11052,   260,   300,  2754, 29892,   409,  6596,   398,\n",
       "           372, 29884,  1827, 29874,    13,   557,   273,  2626,   261,   638,\n",
       "          4977,  6025,   286,   996,   479,   839,   801,  9286, 29884, 19685,\n",
       "          4861, 20694, 21528, 29889,  2261,   574, 29895,  2606,   594, 29874,\n",
       "           282, 10129,   343,   574,    13,  2218,  1590,   348, 29891,  7941,\n",
       "           443, 29873,  2679,  9286, 29884,   289, 10011,   409, 23156,  1794,\n",
       "           288,   280, 29882, 29899,  1772, 29882,  1589,   289, 15547,  1213,\n",
       "            13,  2744,   557,   343,   271,   326,  2930,  8088,   372, 29884,\n",
       "          6035,  1757, 29926,  1450,   370,   972,  6249,  3006,   574,  1460,\n",
       "         29874, 29892,   376, 26729,   557,   273,  1738,  2431,   638, 19585,\n",
       "           801,   972,  6249,    13, 28497,  4812, 25364,   585, 29899, 11311,\n",
       "           585,   594, 29874,  3095, 29874, 29899, 14274,   343,   574,  1827,\n",
       "         29874,   289, 10011, 29889,   922,  5689,   574,  1827, 29874,  5053,\n",
       "           801,  1010,   352, 29899,  6878,   352,   432,  1572,    13, 29885,\n",
       "           996,  1117,   309,  3095, 29874, 29899, 14274, 29889,   317,  9010,\n",
       "           269,   686,  2543, 29882, 29899, 29879,   686,  2543, 29882,  5053,\n",
       "           801,   289, 17951,   431,   271,  6025, 10668,   557,   611,  6905,\n",
       "         11755, 29875,    13, 12873,   557,  2679,   812,  3761,  1213,    13,\n",
       "         29968,   331,   566,   713,  9013, 29895,  3031,   574,   289,  5968,\n",
       "           532, 29892,   376, 29967, 23587,   585,  3856,   279,  1261,   638,\n",
       "           713, 29466,   314, 29884, 29892,  2136, 29874, 12736,   294,  8083,\n",
       "           289, 17698,    13, 29895,  4479,  6025,   639, 29883,   388,   284,\n",
       "           801,   413,  4479,   289,   801, 10011,  9286, 29884,  1010,   352,\n",
       "         29899,  6878,   352, 10668,   557,   263, 11052,  1757,  2764, 29875,\n",
       "           282, 10129,   413,  4479, 11755, 29875,  1213,    13,  2697,   295,\n",
       "           801,  9013, 29895,  3031,   574,   289,  5968,   532,  1261,   638,\n",
       "           713, 29892,  2136, 29874,   385,   557,   343,   271,   326,  2930,\n",
       "          8088,   372, 29884,  6035,  7655,   574, 29895,   271,  8083,    13,\n",
       "          1527,   292, 29887,  2235,   273,   413,   388,   574,   273, 29889,\n",
       "          1394,   574,   413,   388,   574,   273,   372, 29884, 10668,   557,\n",
       "          1757,   657,   801,  1481,   269,  3304,   409, 29895,  2606,   289,\n",
       "           801, 10011,   385,   557,    13, 29891,   271,   326,   282,  1249,\n",
       "         29884,   343,   574,   413,   687,   309,   372, 29884,   594, 29874,\n",
       "          1757, 29891,  1590,   348, 29891,  7941,   282, 10129,   652,  2959,\n",
       "           314, 14757,   574, 29899, 29870,   574,  8092,  1335,   282,  1114,\n",
       "            13, 29873,   398,   277,  1460, 29874, 29889, 10813, 29882,   381,\n",
       "          1460, 29874,   269,  1160,  1794,  8740,   284,   801,   385,   557,\n",
       "           343,   271,   326,  2930,  8088,   372, 29884,   972,  6249,  5535,\n",
       "           314,   271,   652,   413,  1160,   686,  1460, 29874, 29889,    13,\n",
       "         29924,  8245, 29871,   423,  6035,   972,  6249,  2377,  1572,  3813,\n",
       "         29884,   271, 11979,   574, 29889,  3789,   295,   801,  5535,   267,\n",
       "          1794, 29892,  6309,   273,   314,  1460, 29874,   282, 10129,   343,\n",
       "           574,    13, 27774,   332,   262,  3761,   372, 29884,   652, 11979,\n",
       "           574,  1460, 29874, 29889,    13,    13, 17396,   557,   801,  4263,\n",
       "          1794,   286,   595, 29875,   343,   574,  1935, 29881, 26347,  2959,\n",
       "           314,  5697,  7941,   410,  4977,  3534,   275,  1848,   652,   472,\n",
       "           294, 29973,    13,    13, 29909, 29889, 26697,  1794,  1589, 28464,\n",
       "          3333,   273,    13, 29933, 29889, 26697,  1794,  1589,   495,   273,\n",
       "           713,    13, 29907, 29889, 26697,  1794,  1589,  4900, 29926,   332,\n",
       "           273,    13, 29928, 29889, 26697,  1794,   413,   300,   370,   801,\n",
       "           273,    13, 29926,  1450, 21419, 29901,   350,    13,    13,   711,\n",
       "          9761,   361, 29901,   365,   996, 21474, 11052, 10156,   271, 29899,\n",
       "           388,   271,   343,   574,  7655,   638,   329,   972,  6249,  2626,\n",
       "          2638, 29882,   432,  1450, 21419,   343,   574,  5112,   292,  3999,\n",
       "         29884,  1794, 29889,    13,   578,   284,   273, 29901, 12994,   903,\n",
       "          1649, 10345,   801,  4799, 13547,   801,   652, 29882,   424,   279,\n",
       "          1589,  3480,  2518,   435,  1022,   348,   443, 29873,  2679,  3813,\n",
       "           424, 29884, 25016,  4977,  7055,  3274,   289, 15547,  6025,   260,\n",
       "         11445,  4479, 29889,    13, 29909, 29889,   298,   442,  1450,   273,\n",
       "            13, 29933, 29889,   589,   655, 11440,    13, 29907, 29889,   289,\n",
       "         25128,  1450,   273,    13, 29928, 29889,   480, 29895,   598, 10653,\n",
       "           273,    13, 29926,  1450, 21419, 29901]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer([prompt], return_tensors='pt', add_special_tokens=False).to('cuda')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b32bbe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_', '_']\n"
     ]
    }
   ],
   "source": [
    "generate_kwargs = dict(\n",
    "    inputs,\n",
    "    max_new_tokens=3,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.1,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    "    repetition_penalty=1.05,\n",
    ")\n",
    "r = model.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]).split('jawapan:')[-1].strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9649145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]/tmp/ipykernel_398962/821938324.py:2: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  shots = random.sample(arange - {i}, 1)\n",
      "100%|██████████| 54/54 [00:41<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(questions))):\n",
    "    shots = random.sample(arange - {i}, 1)\n",
    "    prompts = []\n",
    "    for no, s in enumerate(shots):\n",
    "        prompts.append(f'Contoh soalan {no + 1}\\n' + convert_prompt(questions[s], answer = True))\n",
    "\n",
    "    prompts.append(convert_prompt(questions[i]))\n",
    "    prompt = '\\n\\n'.join(prompts)\n",
    "    inputs = tokenizer([prompt], return_tensors='pt', add_special_tokens=False).to('cuda')\n",
    "    repeat = []\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            generate_kwargs = dict(\n",
    "                inputs,\n",
    "                max_new_tokens=3,\n",
    "                top_p=0.95,\n",
    "                top_k=50,\n",
    "                temperature=0.5,\n",
    "                do_sample=True,\n",
    "                num_beams=1,\n",
    "                repetition_penalty=1.05,\n",
    "            )\n",
    "            r = model.generate(**generate_kwargs)\n",
    "            r = tokenizer.decode(r[0]).split('jawapan:')[-1].strip().split()\n",
    "            repeat.append(r[0].replace('.', '').replace('</s>', '').split('\\\\')[0].split('/')[0])\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    \n",
    "    questions[i]['output'] = repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03055c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('output-1shot-llama2-13b-32k.json', 'w') as fopen:\n",
    "    json.dump(questions, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dc2a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(l):\n",
    "    return max(set(l), key=l.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04314a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.37037037037037"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = [q for q in questions if 'output' in q]\n",
    "correct = 0\n",
    "for q in filtered:\n",
    "    correct += most_common(q['output']) == q['jawapan']\n",
    "(correct / len(filtered)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb785bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
